#!/usr/bin/env python
__license__ = "MIT"
__version__ = "0.9.3"
__authors__ = ["Marvin Jens","Alex Robertson"]
__email__ = "mjens@mit.edu"

import sys
import itertools
import numpy as np
import copy
import time
import os
import logging
import ska_kmers


class RBNSReads(object):
    def __init__(self, fname, chunklines=2000000):
        self.logger = logging.getLogger('RBNSReads')
        self.logger.info('reading sequences from {fname}'.format(fname=fname) )
        
        # load and keep all sequences in memory (numerically A=0,...T=3 )
        t0 = time.time()
        self.seqm = ska_kmers.read_raw_seqs_chunked(file(fname), chunklines=chunklines)
        self.N, self.L = self.seqm.shape
        t1 = time.time()

        self.logger.info("read {0:.3f}M sequences of length {1} in {2:.1f} seconds".format(self.N/1E6, self.L, (t1-t0) ) )

    def kmer_counts(self, k):
        return ska_kmers.seq_set_kmer_count(self.seqm,k)
    
    def kmer_filter(self, kmer):
        """
        returns the subset of seqm that contains sequences with the desired kmer
        and a boolean matrix with ones at the positions of kmer occurrence
        """
        pass #TODO: implement
    
    def kmer_flank_profiles(self, kmer, k_flank):
        """
        use kmer_filter first and then compute the average occurrences of kmers
        with k=k_flank around the desired "central" kmer.
        """
        pass #TODO: implement


class SKARun(object):
    def __init__(self, reads, max_iterations=10, convergence=0.5, input_run = "", out_path=".", pseudo=1):
        self.logger = logging.getLogger('SKARun')
        self.reads = reads
        self.max_iterations = max_iterations
        self.convergence = convergence
        self.pseudo = pseudo
        self.input_run = input_run
        self.out_path = os.path.abspath(out_path)
        
        # prepare outout path
        if not os.path.exists(self.out_path):
            os.makedirs(self.out_path)


    def stream_counts(self, k):
        self.logger.info("streaming {0}-mers".format(k))
        
        kmers = list(yield_kmers(k))
        background = self.try_load_background_freqs(k)

        t0 = time.time()
        kmer_counts = self.reads.kmer_counts(k) + self.pseudo
        
        t1 = time.time()
        self.logger.debug("counted kmer occurrences in {0:.1f} seconds".format( (t1-t0) ) )

        N = kmer_counts.sum()
        kmer_freqs = np.array(kmer_counts * (4**k)/N, dtype=np.float32)

        current_weights = copy.copy(kmer_freqs)
        
        weight_history = []
        for iteration_i in range(self.max_iterations):
            new_weights = ska_kmers.seq_set_SKA(self.reads.seqm, current_weights, background, k)
                
            weight_history.append(new_weights)
            current_weights = copy.copy(new_weights)
            
            if len(weight_history) > 1:
                delta = weight_history[-1] - weight_history[-2]
                
                change = np.fabs(delta)
                mean_change = change.mean()
                max_i = change.argmax()
                max_change = change[max_i]
                
                self.logger.info("#iteration {0}: mean_change={1} max_change={2} for '{3}' ({4} -> {5})".format(iteration_i, mean_change, max_change, kmers[max_i], weight_history[-2][max_i], weight_history[-1][max_i]))
                if max_change < self.convergence:
                    self.logger.info("reached convergence after {0} iterations".format(iteration_i))
                    break
                
        return current_weights, kmer_freqs


    def try_load_background_freqs(self,k):
        if self.input_run:
            bg_path = os.path.join(self.input_run,"rel_freqs.{0}mer.txt".format(k))
            background = np.array(read_freqs(bg_path), dtype=np.float32)
            self.logger.info("loaded background kmer frequencies from {0}".format(bg_path))
        else:
            background = np.ones(4 ** k, dtype=np.float32)
        
        return background

    def run(self, min_k, max_k):

        for k in range(min_k, max_k+1):
            SKA_weights, kmer_freqs = self.stream_counts(k)
            
            with file(os.path.join(self.out_path, 'SKA_weights.{0}mer.txt'.format(k)), 'w') as of:
                of.write('# kmer\tweight\n')
                for kmer, weight in zip(yield_kmers(k), SKA_weights):
                    of.write('%s\t%g\n' % (kmer, weight))
                of.close()

            with file(os.path.join(self.out_path, 'rel_freqs.{0}mer.txt'.format(k)), 'w') as of:
                of.write('# kmer\trel_freq\n')
                for kmer, freq in zip(yield_kmers(k), kmer_freqs):
                    of.write('%s\t%g\n' % (kmer, freq))
                of.close()
        
        
def read_freqs(src):
    """
    Used to read kmer background frequencies from a previous run on input
    """
    
    f = []
    for line in file(src):
        if line.startswith('#'): 
            continue
        
        parts = line.rstrip().split('\t')

        f.append(float(parts[1]))

    return np.array(f, dtype=np.float32)


def yield_kmers(k):
    """
    An iterater to all kmers of length k in alphabetical order
    """
    bases = 'ACGT'
    for kmer in itertools.product(bases, repeat=k):
        yield ''.join(kmer)


def main():
    from optparse import OptionParser
    usage = "usage: %prog [options] <reads_file> OR cat <reads_file> | %prog [options] /dev/stdin"

    parser = OptionParser(usage=usage)
    parser.add_option("-k","--min-k",dest="min_k",default=3,type=int,help="min kmer size (default=3)")
    parser.add_option("-K","--max-k",dest="max_k",default=8,type=int,help="max kmer size (default=8)")
    
    parser.add_option("-n","--n-passes",dest="n_passes",default=10,type=int,help="max number of passes (default=10)")
    parser.add_option("","--pseudo",dest="pseudo",default=10.,type=float,help="pseudo count to add to kmer counts in order to avoid div by zero for large k (default=10)")
    parser.add_option("-c","--convergence",dest="convergence",default=0.5,type=float,help="convergence is reached when max. change in absolute weight is below this value (default=0.5)")
    parser.add_option("-B","--background", dest="background", default="", help="path to file with background (input) kmer abundances in the library")
    parser.add_option("-o","--output",dest="output",default=".",help="path where results are to be stored")
    parser.add_option("","--debug",dest="debug",default=False, action="store_true",help="SWITCH: activate debug output")
    parser.add_option("","--version",dest="version",default=False, action="store_true",help="SWITCH: show version information and quit")
    options,args = parser.parse_args()

    if options.version:
        print __version__
        print __license__
        print "by", ", ".join(__authors__)
        sys.exit(0)

    if not args:
        parser.error("missing argument: need <reads_file> (or use /dev/stdin)")
        sys.exit(1)

    # set up logging
    log_path = os.path.join(options.output,"run.log")
    if options.debug:
        lvl = logging.DEBUG
    else:
        lvl = logging.INFO

    FORMAT = '%(asctime)-20s\t%(levelname)s\t%(name)s\t%(message)s'
    formatter = logging.Formatter(FORMAT)
    logging.basicConfig(level=lvl, format=FORMAT)    
    root = logging.getLogger('')
    fh = logging.FileHandler(filename=log_path, mode='w')
    fh.setFormatter(logging.Formatter(FORMAT))
    root.addHandler(fh)
    
    logger = logging.getLogger("SKA")
    logger.info("called as '{0}'".format(" ".join(sys.argv)) )

    # run streaming kmer analysis
    ska = SKARun(
        RBNSReads(args[0]), 
        max_iterations = options.n_passes, 
        convergence = options.convergence, 
        input_run = options.background, 
        out_path = options.output, 
        pseudo = options.pseudo
    )
    
    ska.run(options.min_k, options.max_k)
    

if __name__ == '__main__':
    main()
